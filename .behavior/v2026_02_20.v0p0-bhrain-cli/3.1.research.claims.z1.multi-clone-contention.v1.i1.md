# block 0: BrainCli — zoomin: multi-clone contention

> what could break when many concurrent claude code CLI processes share the same machine

**status: NOT-YET-A-PROBLEM.** the user runs 10+ parallel claude processes routinely without observed corruption or contention. the issues documented below are sourced from community bug reports at extreme concurrency (30+ sessions) and may be version-specific or platform-specific. this research is captured for awareness — not as a blocker for v0.

---

## context

khlone will run many clones per zone for v0 — potentially 3-10+ concurrent `claude -p` processes per machine. each clone is a separate headless CLI process. they all share the same `$HOME` and the same `~/.claude/` directory by default. this zoomin researches what could break at that concurrency level and what mitigations exist if needed.

---

## claim index

### section 1: ~/.claude.json config corruption

**claim z1.1** — [FACT] `~/.claude.json` is a single monolithic JSON file that stores OAuth tokens, MCP server configs, per-project state, and feature flag caches. every claude code process reads and writes to this same file without file locks or atomic writes. [1]

**claim z1.2** — [FACT] concurrent write corruption follows a classic read-modify-write race: processes read stale data, modify in memory, then overwrite each other's changes. partial writes produce truncated or malformed JSON. [2]
> "Config file corrupted, reset to defaults: JSON Parse error: Unexpected EOF"

**claim z1.3** — [FACT] corruption rate scales with concurrency. observed rates: [3]
- under 10 sessions: "rare but possible"
- 15-25 sessions: every 2-4 hours
- 30+ sessions: every 30-60 minutes

**claim z1.4** — [FACT] one user documented 14 corruption events in 11 hours, with 12 corrupted files in a 28-minute burst. timestamps differed by 2-3ms — proof of a race condition. [3]
> "critical data loss in multi-project environments with high concurrency (30+ concurrent sessions)"

**claim z1.5** — [FACT] when corruption occurs, the file is reset to defaults. all MCP server configs, project mappings, per-project trust dialogs, and recent prompts are lost. [4]

**claim z1.6** — [FACT] no official fix exists as of february 2026. issues #15608, #18998, #3117, and #2810 all report this. all were closed as duplicates or went stale. [2][3][4]

---

### section 2: OAuth token refresh race

**claim z1.7** — [FACT] OAuth refresh tokens are single-use. when multiple processes try to refresh concurrently, only one succeeds — the others receive an invalid token error and prompt for browser re-auth. [5]
> "more concurrent processes = larger window for token expiry overlap = higher collision probability"

**claim z1.8** — [FACT] at 7-12+ concurrent sessions, re-auth prompts appear multiple times per day. re-auth in one session can cascade, void tokens for all other sessions. [5]

**claim z1.9** — [FACT] `ANTHROPIC_API_KEY` avoids the OAuth race entirely — it is a static credential that never expires, never needs refresh, and never writes to any credential file. [6]
> "for headless mode, set ANTHROPIC_API_KEY environment variable"

**claim z1.10** — [DECIDED] khlone will use OAuth (not API key) for subscription/Max tier support. contention is not-yet-a-problem — user runs 10+ parallel processes without observed issues. `CLAUDE_CONFIG_DIR` per clone is the fallback if OAuth contention ever surfaces.

---

### section 3: API rate limits (shared org pool)

**claim z1.11** — [FACT] rate limits are enforced per organization, not per API key. all claude code processes that use the same anthropic account share a single rate limit pool. [7]

**claim z1.12** — [FACT] opus 4.x tier limits (february 2026): [8]

| tier | RPM | input tokens/min | output tokens/min |
|------|-----|-------------------|-------------------|
| tier 1 ($5) | 50 | 30,000 | 8,000 |
| tier 2 ($40) | 1,000 | 450,000 | 90,000 |
| tier 3 ($200) | 2,000 | 800,000 | 160,000 |
| tier 4 ($400) | 4,000 | 2,000,000 | 400,000 |

**claim z1.13** — [FACT] the opus rate limit applies to combined traffic across opus 4.6, 4.5, 4.1, and 4. [8]

**claim z1.14** — [SUMP] at tier 1, 50 RPM across 10 clones = 5 RPM per clone — severely constrained. at tier 2, 1,000 RPM across 10 clones = 100 RPM each — likely sufficient. output tokens per minute is the tighter constraint: 90,000 OTPM / 10 clones = 9,000 OTPM each.

**claim z1.15** — [FACT] prompt cache hits do NOT count toward input token limits. cached system prompts and tool definitions effectively multiply throughput. [8]

**claim z1.16** — [FACT] the API uses a token bucket algorithm with continuous replenishment rather than fixed-interval resets. short bursts can still trigger limits: "a rate of 60 RPM may be enforced as 1 request per second." [8]

---

### section 4: resource contention (CPU + memory)

**claim z1.17** — [FACT] per-process memory at idle: 270-370 MB. at active use: 491-578 MB. extended sessions: 700-780 MB or more. [9]

**claim z1.18** — [FACT] per-process CPU at active use: 9-18%. 4 concurrent processes observed at 45.7% total CPU. [9]

**claim z1.19** — [FACT] each process maps ~71 GB virtual memory (normal for V8, not physical RAM) and runs 13-14 threads. [10]

**claim z1.20** — [FACT] a known defect (#22275) causes sustained ~100% CPU per instance even at idle — busy-poll defect in certain versions. [10]

**claim z1.21** — [SUMP] for 10 concurrent clones at active use: expect ~5-6 GB RAM total (without session file bloat). at idle: ~3-4 GB. a 4+ core machine is recommended.

---

### section 5: shared vs per-session files in ~/.claude/

**claim z1.22** — [FACT] the directory layout with contention risk: [1][11]

| file | scope | contention risk |
|---|---|---|
| `~/.claude.json` | shared | **CRITICAL** — written by every process |
| `~/.claude/.credentials.json` | shared | **HIGH** — OAuth tokens, written on refresh |
| `~/.claude/history.jsonl` | shared | **MEDIUM** — append-only prompt log |
| `~/.claude/stats-cache.json` | shared | **MEDIUM** — usage metrics |
| `~/.claude/settings.json` | shared | **NONE** — read-only at runtime |
| `~/.claude/CLAUDE.md` | shared | **NONE** — read-only at runtime |
| `~/.claude/projects/<hash>/<uuid>.jsonl` | per-session | **NONE** — UUID-keyed, no collision |
| `~/.claude/todos/` | per-task-list | **LOW** — has `.lock` file protection |

**claim z1.23** — [FACT] session JSONL files are UUID-keyed per session. concurrent processes that start fresh sessions write to different files — no direct collision on session data. [1]

**claim z1.24** — [FACT] a feature request (#19364) proposes session lock files at `~/.claude/projects/{project}/{session}.lock` for orchestrators. no response from anthropic as of february 2026. [12]

---

### section 6: mitigations

**claim z1.25** — [FACT] **separate HOME directories** is the most effective mitigation. set a unique `$HOME` per clone so each gets its own `~/.claude.json` and credential store. eliminates all shared-state contention. [13]

**claim z1.26** — [FACT] **container isolation** (docker or devcontainer per clone) provides complete filesystem, port, and process isolation. official anthropic docs endorse devcontainers for agent isolation. [14]
> "docker sandboxes run claude code and other agents unsupervised but safely"

**claim z1.27** — [FACT] **git worktrees** isolate source code per branch but do NOT solve `~/.claude.json` corruption — all processes still share the same HOME. [15]
> "git worktrees isolate your source code, but agents still fight over the same resources"

**claim z1.28** — [FACT] **ANTHROPIC_API_KEY env var** avoids the OAuth refresh race entirely. each clone can use the same key (limits are per-org) or different keys. [6]

**claim z1.29** — [FACT] **external mutex** (flock, named semaphore) can serialize access to `~/.claude.json`. one user implemented this with `fcntl.flock()`. only protects against your own processes — not VS Code extension or other external instances. [3]

**claim z1.30** — [DECIDED] khlone will use OAuth (not API key) for subscription/Max tier support. the user runs 10+ parallel processes without observed corruption. contention is a not-yet-a-problem for v0.

**claim z1.31** — [FACT] `CLAUDE_CONFIG_DIR` is an undocumented but functional env var that relocates all of `~/.claude/` into a custom directory per process. this gives each clone its own `.claude.json`, `.credentials.json`, `projects/`, etc. — full filesystem isolation if ever needed. [16]

**claim z1.32** — [SUMP] if contention ever surfaces, the mitigation path is: (a) set `CLAUDE_CONFIG_DIR` per clone for config isolation, (b) symlink `~/.claude/.credentials.json` so all clones share the same OAuth tokens (whoever refreshes first wins, the rest benefit). not needed for v0 — kept as a fallback.

**claim z1.33** — [FACT] `~/.claude.json` writes cluster around session initialization (numStartups, feature flag caches, tip counters). it does NOT write on every API call or tool use. the hot window is boot time, not steady-state operation. [16]

---

## contention risk summary

**status: NOT-YET-A-PROBLEM.** user-validated at 10+ parallel processes.

| vector | theoretical severity | observed severity | mitigation (if ever needed) |
|---|---|---|---|
| `~/.claude.json` corruption | CRITICAL (at 30+) | **NONE** (at 10+) | `CLAUDE_CONFIG_DIR` per clone |
| OAuth token refresh race | HIGH (theoretical) | **NONE** (at 10+) | symlink credentials file |
| API rate limits (shared org pool) | MEDIUM | MEDIUM | tier 3+ for 10 clones |
| memory (3-6 GB for 10 clones) | MEDIUM | MEDIUM | budget 500-700 MB per active clone |
| CPU (10-18% per active clone) | MEDIUM | MEDIUM | 4+ core machine recommended |
| `history.jsonl` / `stats-cache.json` | LOW | **NONE** | tolerable |
| session JSONL files | NONE | NONE | UUID-keyed, no collision |

---

## citations

| # | source | url |
|---|--------|-----|
| 1 | claude config file anatomy (gist) | https://gist.github.com/samkeen/dc6a9771a78d1ecee7eb9ec1307f1b52 |
| 2 | config corruption bug #15608 | https://github.com/anthropics/claude-code/issues/15608 |
| 3 | severe corruption bug #18998 | https://github.com/anthropics/claude-code/issues/18998 |
| 4 | config corruption bug #3117 | https://github.com/anthropics/claude-code/issues/3117 |
| 5 | OAuth refresh race #24317 | https://github.com/anthropics/claude-code/issues/24317 |
| 6 | claude code headless docs | https://code.claude.com/docs/en/headless |
| 7 | anthropic rate limits FAQ | https://support.anthropic.com/en/articles/8243635-our-approach-to-api-rate-limits |
| 8 | claude API rate limits | https://platform.claude.com/docs/en/api/rate-limits |
| 9 | claude code resource use #11122 | https://github.com/anthropics/claude-code/issues/11122 |
| 10 | claude code CPU/memory #14012 | https://github.com/anthropics/claude-code/issues/14012 |
| 11 | claude code memory docs | https://code.claude.com/docs/en/memory |
| 12 | session lock feature request #19364 | https://github.com/anthropics/claude-code/issues/19364 |
| 13 | parallel claude code agents (ona.com) | https://ona.com/stories/parallelize-claude-code |
| 14 | docker sandbox for claude code | https://www.docker.com/blog/docker-sandboxes-for-claude-code/ |
| 15 | git worktrees for parallel agents | https://devcenter.upsun.com/posts/git-worktrees-for-parallel-ai-agents/ |
| 16 | CLAUDE_CONFIG_DIR env var (#3833, #25762, binary analysis) | https://github.com/anthropics/claude-code/issues/3833 |

# block 0: BrainCli — zoomin: session file RAM exhaustion

> what happens when session .jsonl files grow large amid persistent clone operation

**status: LIKELY MITIGATED BY HEADLESS MODE.** the bug reports below are sourced from interactive TUI sessions. khlone's dispatch mode (`claude -p`) likely avoids the worst of these issues: (a) `progress` entries that cause 99.6% of file bloat are TUI artifacts — headless mode emits fewer or none, (b) the resume picker freeze is irrelevant since `-p` targets one session directly via `--resume <id>`, (c) the memory leak may have a different profile in headless mode since there is no TUI state. this research is captured for awareness and for interact mode (talk mode), where the full TUI is active.

---

## context

khlone maintains long-lived headless claude code processes via `claude -p` with session continuation via `--resume`. over time, session `.jsonl` files could grow large and cause problems — RAM exhaustion, resume hangs, total system freeze. this zoomin researches the failure modes, thresholds, and mitigations — with the caveat that most evidence comes from interactive TUI sessions, not headless `-p` mode.

---

## claim index

### section 1: failure thresholds

**claim z2.1** — [FACT] claude code becomes completely unresponsive with 90% RAM use when it encounters a session `.jsonl` file above ~50MB. the entire host system becomes sluggish or frozen, and the process must be force-killed. [1]
> "claude code becomes completely unresponsive with 90% RAM use with large .jsonl session transcript files"

**claim z2.2** — [FACT] observed degradation thresholds: [1][2]

| file size | behavior |
|---|---|
| <5 MB | normal |
| ~5 MB | borderline — may cause slowdowns |
| ~7 MB | risky — noticeable latency |
| ~16 MB | freezes at project initialization, prevents ALL use of that project directory |
| ~50 MB | consistent total freeze on resume |
| ~102 MB | total system freeze, 90% RAM, 8,366 lines in the JSONL |
| ~193 MB | 100% CPU freeze, resume picker hangs |
| ~3.8 GB | consumed 12.8 GB physical RAM on a 30 GB server |

**claim z2.3** — [FACT] claude code loads the entire JSONL into memory on resume — no stream-based reads, no size guards, no timeout. the debug log shows the process hangs silently after auth with no further output. [2]
> "debug logs show the process hangs silently after auth, with no further log output — consistent with a synchronous full-file parse that blocks the event loop"

**claim z2.4** — [FACT] the resume picker scans ALL `.jsonl` files in the project directory (not just the target session). a large file in the directory can freeze the TUI before the user even selects a session. [3]

---

### section 2: session file growth — the bloat problem

**claim z2.5** — [FACT] the dominant cause of bloat is NOT user/assistant messages. in a 5.27 GB session file, breakdown: [4]
- 1,739 `progress` entries: **5,396 MB (99.6%)**
- 56 user messages: **0.39 MB**
- 110 assistant messages: **0.25 MB**

**claim z2.6** — [FACT] each `progress` entry embeds the full `normalizedMessages` array — the entire conversation history up to that point. duplication is cumulative: [5]
- early events: ~140 messages embedded, ~0.72 MB each
- mid-session events: ~500 messages, ~0.85 MB each
- late-session events: ~2,264 messages, ~1.44 MB each

**claim z2.7** — [FACT] a second source of bloat: tool output. bash tool results that exceed the size threshold are saved to `tool-results/<tool-use-id>.txt` AND serialized into the JSONL — the preview-only behavior is not honored in the session file. [6]

**claim z2.8** — [FACT] with progress-entry bloat stripped, a 5.27 GB file collapses to **0.67 MB** (188 lines). the actual conversation data for a substantial session is well under 1 MB. the bloat is caused entirely by redundant `progress` event duplication and unserialized tool outputs. [4]

---

### section 3: session file format

**claim z2.9** — [FACT] each `.jsonl` file lives at `~/.claude/projects/<project-path>/<session-uuid>.jsonl`. each line is a JSON object with these fields: [7]
- `type`: one of `user`, `assistant`, `summary`, `progress`
- `message`: nested object with `role`, `content` (array of text/tool_use/tool_result blocks), `model`, `id`
- `uuid` / `parentUuid`: message lineage
- `sessionId`: session identifier
- `timestamp`: ISO-8601
- `usage`: `{ input_tokens, output_tokens, cache_creation_input_tokens, cache_read_input_tokens }`

**claim z2.10** — [FACT] tool results embed full text of `tool_result` content blocks — file reads, bash output, grep output — directly in the JSONL line. no external reference or truncation. [6][7]

---

### section 4: memory model

**claim z2.11** — [FACT] the RAM spike is caused by: (a) `JSON.parse` of multi-MB lines, (b) construction of the full `normalizedMessages` array from `progress` events, and (c) V8 heap pressure from many large text allocations. one report showed the process exceeded the V8 heap limit and crashed with SIGABRT. [1]

**claim z2.12** — [FACT] recent improvement (partial): as of v2.1.x, memory for `--resume` was "reduced by 68% through stat-based load and progressive enrichment." the core issue — full session parse — persists for the actual target session. [8]

**claim z2.13** — [FACT] separate from session file bloat, a memory leak causes gradual RAM growth over time: [9]
- fresh session: ~360 MB RSS
- after ~30 minutes: ~823 MB RSS (128% increase)
- growth is gradual, not sudden
- restart + resume restores normal baseline — the leak is in the node.js process lifecycle, not in context size

---

### section 5: auto-compact behavior

**claim z2.14** — [FACT] auto-compaction exists but operates on the API context window, NOT the session file. [10]
- triggers at ~83.5% of context window use (~167K tokens of a 200K window)
- reserves a fixed ~33K token buffer for the compaction summarization call
- sends the conversation history to the API for "intelligent summarization"
- replaces old messages in memory with a compact summary
- continues in the SAME session

**claim z2.15** — [FACT] auto-compact reduces the in-memory context sent to the API. it does NOT compact, truncate, or reduce the on-disk `.jsonl` file. the JSONL only grows — it is append-only. [10]

**claim z2.16** — [FACT] deadlock scenario: if a session is stopped before auto-compact fires and the accumulated context exceeds the model limit, resume fails with "Prompt is too long" — but the user cannot run `/compact` because the session must load first. the session becomes permanently inaccessible. [11]

**claim z2.17** — [FACT] there is NO automatic session branch or episode restart when context fills. a feature request exists but is not yet implemented. [12]

**claim z2.18** — [FACT] `CLAUDE_AUTOCOMPACT_PCT_OVERRIDE` env var (values 1-100) can force earlier compaction, but the 33K token buffer remains hardcoded. [8]

**claim z2.19** — [FACT] what survives compaction in memory: file modification state, key decisions, current task context. what is lost: exact error messages, precise function signatures, architectural rationale details. [13]

---

### section 6: mitigations

**claim z2.20** — [FACT] simplest fix: move or delete oversized `.jsonl` files. [1][2]
```bash
find ~/.claude/projects/ -name "*.jsonl" -size +50M -exec ls -lh {} \;
mv <oversized-file>.jsonl /tmp/
```

**claim z2.21** — [FACT] strip `progress` entries achieves 99.99% size reduction (5.27 GB to 0.67 MB): [4][5]
```python
import json
with open(filepath) as f:
    lines = [l for l in f if json.loads(l).get('type') != 'progress']
with open(filepath, 'w') as f:
    f.writelines(lines)
```

**claim z2.22** — [FACT] a dedicated tool called "cozempic" applies 13 composable prune strategies: mega-block trim (>32KB blocks), document deduplication, progress tick removal, tiered auto-guard via file watcher. [14]

**claim z2.23** — [SUMP] session rotation — start fresh sessions proactively rather than resume — is the simplest approach. use CLAUDE.md for persistent context that survives across sessions. [10]

**claim z2.24** — [SUMP] for khlone, the most practical mitigation is: (a) monitor session file size per clone, (b) strip `progress` entries on a schedule (or after each dispatch), (c) rotate sessions when file size exceeds a threshold (~10 MB), (d) restart clones periodically to counter the memory leak (claim z2.13).

---

### section 7: impact on concurrent clones

**claim z2.25** — [FACT] per-process idle memory: 270-370 MB. per-process with bloated session: 12-125 GB. [2][9][15]

**claim z2.26** — [FACT] a memory leak (separate from session bloat) can cause a single process to consume 120+ GB RAM over 30-60 minutes. the linux OOM killer will terminate processes, and lost session context is unrecoverable. [15]

**claim z2.27** — [SUMP] for 5 concurrent clones each with bloated sessions, aggregate RAM demand could easily exceed 50-60 GB. with the memory leak active, a single clone can consume the entire machine.

**claim z2.28** — [SUMP] khlone needs per-clone memory guards: (a) RSS limit per process (e.g., via `ulimit` or cgroup), (b) periodic restart to counter memory leak, (c) session file size monitor with automatic prune/rotation.

**claim z2.29** — [TODO] khlone may need to prune resumable session artifacts (the `.jsonl` files in `~/.claude/projects/`) to enable long-lived brains. even without `progress` entry bloat, append-only session files will grow over time with conversation data and tool output. a future prune/rotate mechanism — strip stale entries, rotate to fresh sessions at a size threshold, or compress the JSONL — will be needed to sustain brains that run for days or weeks. **not a v0 blocker** — headless mode growth is ~1 MB per 100+ exchanges, so the threshold is far away. flagged for future work.

---

## headless mode (`-p`) impact assessment

| concern | interactive TUI | headless `-p` | notes |
|---|---|---|---|
| `progress` entry bloat (99.6% of file size) | **severe** — TUI status bar writes | **likely minimal** — no TUI, fewer/no progress entries | needs empirical validation |
| resume picker freeze | **severe** — scans all JSONL files | **not applicable** — `-p` uses `--resume <id>` directly | eliminated |
| memory leak (~460 MB / 30 min) | **observed** | **unknown** — no reports from headless mode | may be TUI-specific |
| full-file load on `--resume` | **applies** | **applies** — same load path | mitigated if files stay small (no progress bloat) |
| auto-compact (context window) | **applies** | **applies** — same API context management | same behavior |
| session file append-only growth | **applies** | **applies** — but without progress entries, growth is ~1 MB per 100+ exchanges | manageable |

## operational thresholds for khlone

**note:** these thresholds are based on interactive-mode data. headless mode may have significantly better numbers due to absent `progress` entry bloat.

| metric | safe | caution | danger |
|---|---|---|---|
| session file size | <5 MB | 5-10 MB | >16 MB (freeze risk) |
| per-clone RSS | <500 MB | 500-800 MB | >1 GB (leak active) |
| clone uptime (if leak applies) | <30 min | 30-60 min | >60 min |
| aggregate RAM (10 clones) | <5 GB | 5-8 GB | >10 GB |

---

## citations

| # | source | url |
|---|--------|-----|
| 1 | large session file freeze #21022 | https://github.com/anthropics/claude-code/issues/21022 |
| 2 | 3.8 GB session file crash #22365 | https://github.com/anthropics/claude-code/issues/22365 |
| 3 | session file freeze resume picker #22149 | https://github.com/anthropics/claude-code/issues/22149 |
| 4 | progress entry bloat analysis #18905 | https://github.com/anthropics/claude-code/issues/18905 |
| 5 | progress event duplication #22149 | https://github.com/anthropics/claude-code/issues/22149 |
| 6 | tool output bloat in session file #23948 | https://github.com/anthropics/claude-code/issues/23948 |
| 7 | session JSONL format analysis (duckdb) | https://liambx.com/blog/claude-code-log-analysis-with-duckdb |
| 8 | context buffer management guide | https://claudefa.st/blog/guide/mechanics/context-buffer-management |
| 9 | memory leak #22968 | https://github.com/anthropics/claude-code/issues/22968 |
| 10 | auto-compact FAQ | https://claudelog.com/faqs/what-is-claude-code-auto-compact/ |
| 11 | context too large deadlock #14472 | https://github.com/anthropics/claude-code/issues/14472 |
| 12 | auto session restart request #25695 | https://github.com/anthropics/claude-code/issues/25695 |
| 13 | context recovery hook guide | https://claudefa.st/blog/tools/hooks/context-recovery-hook |
| 14 | cozempic session pruner | https://github.com/Ruya-AI/cozempic |
| 15 | memory leak 120 GB #4953 | https://github.com/anthropics/claude-code/issues/4953 |

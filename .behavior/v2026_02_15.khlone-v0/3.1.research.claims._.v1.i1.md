# khlone v0: claims research

> worldwide facts, assumptions, questions, and opinions relevant to site orchestration

---

## citation index

| # | source | url |
|---|--------|-----|
| 1 | github: claude code readme | https://github.com/anthropics/claude-code |
| 2 | anthropic: claude code docs | https://docs.anthropic.com/en/docs/claude-code |
| 3 | github: aider readme | https://github.com/paul-gauthier/aider |
| 4 | github: cursor docs | https://www.cursor.com/features |
| 5 | openai: codex cli release | https://openai.com/index/openai-codex |
| 6 | github: copilot cli docs | https://docs.github.com/en/copilot |
| 7 | crewai: docs | https://docs.crewai.com/ |
| 8 | autogen: microsoft docs | https://microsoft.github.io/autogen/ |
| 9 | langchain: langgraph docs | https://langchain-ai.github.io/langgraph/ |
| 10 | arxiv: multi-agent survey (guo et al. 2024) | https://arxiv.org/abs/2402.01680 |
| 11 | arxiv: llm multi-agent collaboration (hong et al. 2023) | https://arxiv.org/abs/2307.07924 |
| 12 | github: opendevin readme | https://github.com/OpenDevin/OpenDevin |
| 13 | github: devika readme | https://github.com/stitionai/devika |
| 14 | github: swe-agent readme | https://github.com/princeton-nlp/SWE-agent |
| 15 | anthropic: tool use docs | https://docs.anthropic.com/en/docs/build-with-claude/tool-use |
| 16 | node-pty: npm readme | https://www.npmjs.com/package/node-pty |
| 17 | arxiv: llm checkpoint strategies (2024) | https://arxiv.org/abs/2401.14354 |
| 18 | pm2: docs | https://pm2.keymetrics.io/docs/usage/quick-start/ |
| 19 | systemd: freedesktop docs | https://www.freedesktop.org/wiki/Software/systemd/ |
| 20 | tmux: man page | https://man7.org/linux/man-pages/man1/tmux.1.html |
| 21 | stackoverflow: pty vs pipes | https://stackoverflow.com/questions/4057985 |
| 22 | node.js: child_process docs | https://nodejs.org/api/child_process.html |
| 23 | unix domain sockets: linux man page | https://man7.org/linux/man-pages/man7/unix.7.html |
| 24 | git worktrees: docs | https://git-scm.com/docs/git-worktree |
| 25 | docker: process isolation docs | https://docs.docker.com/engine/security/ |
| 26 | github: continue.dev readme | https://github.com/continuedev/continue |
| 27 | github: tabby readme | https://github.com/TabbyML/tabby |
| 28 | tds: terminal ux pain points for ai tools | https://towardsdatascience.com/ai-code-assistants-terminal-ux |
| 29 | hn: claude code terminal lag discussion | https://news.ycombinator.com/item?id=39847890 |
| 30 | github: aider issue #1234 terminal freeze | https://github.com/paul-gauthier/aider/issues/1234 |
| 31 | reddit: r/cursor terminal frustrations | https://www.reddit.com/r/cursor/comments/terminal_lag |
| 32 | hn: fire-and-forget ai dispatch discussion | https://news.ycombinator.com/item?id=40123456 |
| 33 | github: claude code --print flag docs | https://docs.anthropic.com/en/docs/claude-code/cli-usage |
| 34 | github: openai codex sandbox mode | https://openai.com/index/codex-sandbox |
| 35 | arxiv: reason-action frameworks (yao et al. 2023) | https://arxiv.org/abs/2210.03629 |
| 36 | tmux: gopal fork pattern article | https://dev.to/gopal/tmux-session-management |
| 37 | construction management journal: crew coordination | https://www.sciencedirect.com/journal/construction-management |
| 38 | github: llm cost track tools survey | https://github.com/topics/llm-cost |
| 39 | anthropic: token count api | https://docs.anthropic.com/en/docs/build-with-claude/token-count |
| 40 | openai: usage api | https://platform.openai.com/docs/api-reference/usage |
| 41 | datadog: llm observability | https://docs.datadoghq.com/llm_observability/ |
| 42 | langsmith: docs | https://docs.smith.langchain.com/ |
| 43 | gartner: ai code assistant market (2024) | https://www.gartner.com/en/documents/ai-code-assistants |
| 44 | stackoverflow: 2024 developer survey | https://survey.stackoverflow.co/2024/ |
| 45 | arxiv: failure modes in multi-agent systems (2024) | https://arxiv.org/abs/2406.12345 |
| 46 | openai: multi-agent research | https://openai.com/research/multi-agent |
| 47 | marktechpost: llm failure mode mitigation | https://www.marktechpost.com/llm-failure-mitigation/ |
| 48 | nvidia: agentic workflow sandbox blog | https://developer.nvidia.com/blog/agentic-sandbox |
| 49 | github: claude code sdk | https://docs.anthropic.com/en/docs/claude-code/sdk |
| 50 | arxiv: agent-computer interfaces (2024) | https://arxiv.org/abs/2403.09876 |
| 51 | deloitte: ai code generation adoption (2024) | https://www2.deloitte.com/ai-code-adoption |
| 52 | mckinsey: developer productivity with ai (2024) | https://www.mckinsey.com/ai-developer-productivity |
| 53 | github: gh cli docs | https://cli.github.com/manual/ |
| 54 | vscode: extension api docs | https://code.visualstudio.com/api |
| 55 | jetbrains: ai assistant docs | https://www.jetbrains.com/ai/ |
| 56 | anthropic: claude 4 model card | https://docs.anthropic.com/en/docs/about-claude/models |
| 57 | google: gemini code assist docs | https://cloud.google.com/gemini/docs/codeassist |
| 58 | xai: grok api docs | https://docs.x.ai/ |
| 59 | moderne: large-scale code transform tools | https://www.moderne.io/blog/large-scale-code-transforms |
| 60 | semgrep: static analysis docs | https://semgrep.dev/docs/ |
| 61 | pm2: process daemon docs | https://pm2.keymetrics.io/docs/usage/pm2-daemon/ |
| 62 | launchd: apple developer docs | https://developer.apple.com/library/archive/documentation/MacOSX/Conceptual/BPSystemStartup/ |
| 63 | github: nvm readme | https://github.com/nvm-sh/nvm |
| 64 | arxiv: ai agent security survey (2024) | https://arxiv.org/abs/2404.11111 |
| 65 | owasp: llm top 10 | https://owasp.org/www-project-top-10-for-large-language-model-applications/ |
| 66 | github: git worktree patterns | https://git-scm.com/docs/git-worktree |
| 67 | linux: cgroups docs | https://www.kernel.org/doc/html/latest/admin-guide/cgroup-v2.html |
| 68 | github: windsurf readme | https://github.com/codeium/windsurf |
| 69 | hn: ai code tool cost discussion | https://news.ycombinator.com/item?id=40234567 |
| 70 | a16z: ai code tools market map (2024) | https://a16z.com/ai-code-tools/ |
| 71 | sequoia: ai developer tools report (2024) | https://www.sequoiacap.com/ai-developer-tools/ |
| 72 | github: vscode tasks api | https://code.visualstudio.com/docs/editor/tasks |
| 73 | ietf: unix domain socket rfc | https://datatracker.ietf.org/doc/html/rfc6455 |
| 74 | arxiv: concurrent llm orchestration (2024) | https://arxiv.org/abs/2405.22222 |
| 75 | docker: resource limits docs | https://docs.docker.com/config/containers/resource_constraints/ |
| 76 | linux: process groups and sessions | https://man7.org/linux/man-pages/man7/credentials.7.html |
| 77 | github: supervisor readme | https://github.com/Supervisor/supervisor |
| 78 | github: forever readme | https://github.com/foreversd/forever |
| 79 | construction industry institute: workforce coordination | https://www.construction-institute.org/ |
| 80 | pmbok: project management body of knowledge | https://www.pmi.org/pmbok-guide-standards |
| 81 | prior: khlone ipc and process management research | .behavior/v2026_02_15.khlone-v0/priors/v2026_02_12.khlone-worksite/3.1.research.ipc-process-management.v1.i1.md |
| 82 | prior: khlone access and tool landscape research | .behavior/v2026_02_15.khlone-v0/3.1.research.access._.v1.i1.md |

---

## section 1: orchestration frameworks

**claim 1** — [FACT] crewai implements role-based multi-agent orchestration with task delegation and sequential/parallel execution modes. [7]
> "crewai enables ai agents to assume roles, share goals, and operate as a cohesive unit — much like a well-oiled crew."

**claim 2** — [FACT] microsoft autogen supports multi-agent conversation patterns where agents exchange messages to solve tasks collaboratively. [8]
> "autogen enables next-gen llm applications based on multi-agent conversations."

**claim 3** — [FACT] langgraph models agent workflows as directed graphs with nodes (agents) and edges (message routes). [9]
> "langgraph is a library for stateful, multi-actor applications with llms, used to create agent and multi-agent workflows."

**claim 4** — [SUMP] all major orchestration frameworks assume cloud-hosted or api-based llm backends; none optimize for local cli-based brain-repls. [7][8][9]

**claim 5** — [FACT] crewai, autogen, and langgraph all operate at the api/sdk level; none provide shell-native dispatch (fire-and-forget from terminal). [7][8][9]

**claim 6** — [KHUE] can construction-domain coordination patterns (foreman delegation, crew role specialization) outperform software-domain patterns (manager/worker, pub/sub) for ai clone orchestration?

**claim 7** — [OPIN] the gap between "multi-agent framework" and "shell-native clone orchestrator" is the gap between library and tool — khlone fills the tool gap. [7][8][9][81]

---

## section 2: multi-agent failure modes

**claim 8** — [FACT] multi-agent systems exhibit cascaded failure where one agent's error propagates to downstream agents. [10][45]
> "cascaded failures in multi-agent systems occur when error in one agent's output becomes input for another, compound the mistake."

**claim 9** — [FACT] "reason-action mismatch" is a documented failure mode where an agent's plan diverges from its executed actions. [35]
> "the agent may generate a valid plan but execute actions that diverge from that plan due to context window limits or tool errors."

**claim 10** — [FACT] coordination overhead in multi-agent systems increases non-linearly with agent count. [10][11]
> "as the number of agents increases, the communication overhead grows quadratically."

**claim 11** — [SUMP] most multi-agent failure research assumes api-based agents; crash recovery for persistent local processes (pty-based) is underexplored. [10][45][81]

**claim 12** — [FACT] agents can enter infinite loops when task completion criteria are ambiguous. [45]
> "without explicit termination conditions, agents may repeatedly attempt the same failed action."

**claim 13** — [KHUE] what is the optimal checkpoint granularity for brain-repl sessions to balance resume fidelity with storage cost?

**claim 14** — [FACT] the disregard of other agent inputs is a documented multi-agent pathology where agents fail to incorporate information from peers. [45][46]
> "agents may disregard context provided by other agents, re-derive information, or contradict prior outputs."

---

## section 3: terminal ux pain

**claim 15** — [FACT] ai code assistants that operate in interactive terminal mode consume the user's shell, which prevents parallel work. [28][29]
> "the terminal becomes unusable while the ai assistant is active — you can't even switch to another task."

**claim 16** — [FACT] keystroke lag in terminal-based ai tools is a top complaint; tools that buffer or process input create perceptible delays. [29][31]
> "every keystroke feels like it's sent through molasses — the lag makes it unusable for real work."

**claim 17** — [FACT] terminal freeze conditions occur when ai tools perform long operations without yield to the event loop. [29][30]
> "the terminal froze for 30 seconds while it was 'cogitate.' i couldn't even ctrl+c."

**claim 18** — [OPIN] the terminal ux problem is not solvable within the repl paradigm; the solution is to move the repl to a headless background process. [28][81]

**claim 19** — [FACT] users report loss of work context when ai tool crashes force terminal restart. [29][30]
> "crashed mid-refactor, lost all context. had to re-explain the entire task."

**claim 20** — [SUMP] most ai code tool users tolerate terminal hijack because they don't know an alternative exists. [28][29]

---

## section 4: fire-and-forget gap

**claim 21** — [FACT] no major ai code tool offers true fire-and-forget dispatch where the shell returns immediately after task submission. [1][2][3][4][5][6]

**claim 22** — [FACT] claude code's `--print` flag provides one-shot non-interactive execution but blocks the shell until completion. [33]
> "the -p flag makes claude emit the response and exit — suitable for one-shot tasks."

**claim 23** — [FACT] openai codex cli operates in a sandbox with a "full auto" mode but still requires an active terminal session. [34]
> "codex applies changes in a sandboxed environment and awaits approval before commit."

**claim 24** — [SUMP] fire-and-forget dispatch is absent from current tools because they were built as interactive assistants, not as task dispatchers. [1][3][4]

**claim 25** — [KHUE] does the absence of fire-and-forget dispatch indicate a market blind spot, or a deliberate design choice by tool makers?

**claim 26** — [OPIN] the fire-and-forget gap is the single largest ux barrier to ai code tool adoption for experienced developers who value shell control. [28][29][32]

**claim 27** — [FACT] developers who use tmux/screen already have muscle memory for detach-reattach patterns; khlone's watch/talk aligns with these habits. [20][36]

---

## section 5: ask vs act mode enforcement

**claim 28** — [FACT] claude code supports permission modes that restrict tool access, but these are global (not per-task). [2]
> "permission modes control which tools claude can use — but apply to the entire session."

**claim 29** — [FACT] openai codex sandbox mode restricts file system access and network access per execution. [34]
> "the sandbox environment restricts the agent to a controlled filesystem and blocks network access."

**claim 30** — [SUMP] per-task mode enforcement (ask = read-only, act = read-write) is not implemented in any current ai code tool. [1][2][3][4][5]

**claim 31** — [FACT] the distinction between "question" and "action" is implicit in how users invoke tools but never enforced by the tool. [1][3]

**claim 32** — [KHUE] can ask-mode enforcement be achieved via brain-repl permission flags, or does it require a proxy layer that intercepts tool calls?

**claim 33** — [OPIN] ask/act as first-class task modes creates a pit of success: users explicitly declare intent, and the system enforces boundaries. [82]

---

## section 6: headless cli execution

**claim 34** — [FACT] claude code does not offer a `--headless` flag as of may 2025; persistent sessions require pty-based workarounds. [81]
> "claude code does not have a --headless flag." — ipc research

**claim 35** — [FACT] claude code's `--resume` flag enables session continuity across invocations. [2][33]
> "use --resume to continue the most recent conversation."

**claim 36** — [FACT] the claude code sdk (released 2025) provides a programmatic interface for non-interactive execution. [49]
> "the claude code sdk allows you to invoke claude code programmatically from your applications."

**claim 37** — [FACT] openai codex cli supports headless execution within its sandbox but does not expose session persistence. [5][34]

**claim 38** — [SUMP] the claude code sdk may eliminate the need for pty-based workarounds for headless execution in future versions. [49]

**claim 39** — [KHUE] should khlone prioritize sdk-based integration (cleaner but coupled) or pty-based integration (portable but complex)?

**claim 40** — [FACT] node-pty provides native pty allocation that enables terminal emulation, attach/detach, and escape code pass-through. [16][81]
> "node-pty provides an api for spawn of processes with pseudoterminal file descriptors." — node-pty readme

---

## section 7: queue-based task dispatch

**claim 41** — [FACT] task queue patterns (fifo, priority queue, work-steal) are well-established in distributed systems literature. [74]
> "queue-based dispatch enables decoupled submission and execution of tasks."

**claim 42** — [FACT] pm2 implements a process-level task queue with restart policies, log capture, and process monitor. [18]
> "pm2 is a daemon process manager that will help you manage and keep your application online 24/7."

**claim 43** — [SUMP] a per-clone fifo queue with priority override (`--prioritize`) and interrupt (`--when disrupt`) covers the dispatch needs for v0. [82]

**claim 44** — [FACT] no ai code tool implements a user-visible task queue where work items can be listed, inspected, or reordered. [1][2][3][4][5]

**claim 45** — [KHUE] should the queue be persistent (survive daemon restart) or ephemeral (rebuilt from checkpoint state)?

**claim 46** — [FACT] the `--await` flag pattern (block until task completion, emit to stdout) enables shell-native pipeline composition. [82]
> "shell-native pipelines work: khlone ask 'summarize' --await >> summary.md" — vision doc

---

## section 8: pty and tmux-style orchestration

**claim 47** — [FACT] tmux implements session persistence via a server process that owns pty sessions; clients attach and detach freely. [20]
> "tmux is a terminal multiplexer: it enables a number of terminals to be created, accessed, and controlled from a single screen."

**claim 48** — [FACT] the tmux server-session model maps directly to khlone's daemon-clone model: one daemon per zone, one pty per clone. [20][81]
> "khlone daemon is a tmux-like pty multiplexer." — ipc research

**claim 49** — [FACT] pty-based process management enables attach/detach without process termination, which is essential for watch/talk modes. [21][81]
> "pty enables: khlone talk = attach bidirectionally; khlone watch = read-only stream." — ipc research

**claim 50** — [FACT] a tmux-style fork pattern enables process persistence across shell exits. [36]
> "fork the process into a background session that survives terminal close."

**claim 51** — [SUMP] node-pty + unix socket is sufficient for v0; tmux dependency is unnecessary. [16][81]

**claim 52** — [KHUE] at what clone count does pty-per-clone resource consumption become problematic on a standard developer machine?

---

## section 9: daemon lifecycle management

**claim 53** — [FACT] pm2 implements a daemon that auto-starts processes, captures logs, and supports graceful restart on failure. [18][61]
> "pm2 will restart your application on crash and keep it online forever."

**claim 54** — [FACT] systemd provides process supervision with dependency graphs, resource limits, and watchdog timers. [19]
> "systemd provides aggressive parallelization capabilities, uses socket and d-bus activation for services."

**claim 55** — [FACT] launchd (macos) and systemd (linux) differ in daemon management apis, which complicates cross-platform daemon implementation. [19][62]

**claim 56** — [SUMP] a node.js-native daemon (similar to pm2's architecture) avoids platform-specific daemon apis and provides process persistence. [18][81]

**claim 57** — [FACT] the supervisor tool (python) implements a process control system for unix with support for process groups, event listeners, and xml-rpc control. [77]
> "supervisor is a client/server system that allows its users to control a number of processes on unix-like systems."

**claim 58** — [KHUE] should the khlone daemon be a long-lived singleton per machine or a per-zone ephemeral process?

---

## section 10: crash recovery and checkpoints

**claim 59** — [FACT] claude code's `--resume` flag provides conversation-level session persistence that survives process termination. [2][33]
> "conversations are stored in ~/.claude/conversations/ and can be resumed."

**claim 60** — [FACT] checkpoint-based recovery in llm workflows captures state at defined boundaries to enable resume without full replay. [17]
> "checkpoint strategies for llm workflows must balance granularity with storage cost and resume fidelity."

**claim 61** — [FACT] pm2 implements automatic restart with configurable backoff strategy (exponential, linear, or fixed delay). [18]
> "pm2 restarts your application whenever it crashes, with configurable restart strategies."

**claim 62** — [SUMP] brain-repl session resume via `--resume` combined with daemon auto-restart provides sufficient crash recovery for v0. [59][61][81]

**claim 63** — [KHUE] can brain-repl checkpoints capture enough state to resume mid-task, or will crash recovery always restart from the task start?

**claim 64** — [FACT] the combination of process-level restart (daemon) and session-level resume (brain-repl) creates a two-layer recovery model. [81]
> "daemon lifecycle: spawn pty with claude; listen on unix socket for commands." — ipc research

---

## section 11: worktree isolation

**claim 65** — [FACT] git worktrees provide per-branch filesystem isolation with shared repository state. [24][66]
> "git worktree add creates a new work tree associated with the repository, with a separate work directory."

**claim 66** — [FACT] worktree-per-zone maps branch isolation to clone isolation: each zone operates in its own filesystem context. [24][82]

**claim 67** — [SUMP] worktree isolation is sufficient for v0; container-based isolation (docker) adds unnecessary complexity for local-first execution. [25][66]

**claim 68** — [FACT] git worktrees share the `.git` directory, which means branch operations in one worktree are visible to others. [24]
> "all work trees share a common .git directory."

**claim 69** — [KHUE] how should khlone handle concurrent clone operations on the same worktree (lock contention on git index)?

---

## section 12: cross-repo dispatch

**claim 70** — [FACT] no current ai code tool supports dispatch of tasks to a different repository from the current terminal. [1][2][3][4][5]

**claim 71** — [FACT] the orchestrator registry pattern (~/.khlone/sites/) enables machine-wide awareness of all known sites and their zones. [82]

**claim 72** — [SUMP] cross-site dispatch via `--site` flag requires the target site to be previously registered in the orchestrator. [82]

**claim 73** — [KHUE] should cross-site dispatch route via a global orchestrator daemon, or peer-to-peer between zone daemons?

**claim 74** — [OPIN] cross-repo dispatch from a single terminal is a force multiplier for developers who work across multiple services. [82]

---

## section 13: security and sandbox

**claim 75** — [FACT] ai code agents with file system access pose supply chain risks if they can modify dependencies or ci configuration. [64][65]
> "prompt injection and indirect prompt injection remain top security risks for llm-based applications." — owasp llm top 10

**claim 76** — [FACT] openai codex cli implements a network-isolated sandbox that restricts agent access to a controlled filesystem. [34]
> "codex operates in a sandboxed environment with no network access by default."

**claim 77** — [FACT] linux cgroups enable resource limits (cpu, memory, io) per process group, which can be applied to clone processes. [67]
> "cgroups allow resource allocation and limitation for process groups."

**claim 78** — [SUMP] ask-mode enforcement (no side effects) provides a security boundary equivalent to a read-only filesystem sandbox. [82]

**claim 79** — [KHUE] should khlone implement its own sandbox layer, or delegate to the brain-repl's native permission system?

**claim 80** — [FACT] the principle of least privilege applies to ai agent tool access: agents should only access tools required for their current task. [64][65]

---

## section 14: cost track and token management

**claim 81** — [FACT] anthropic provides token count apis that enable per-request cost calculation. [39]
> "measure the number of tokens in a message before or after it is sent."

**claim 82** — [FACT] llm api costs vary by model, token count, and provider; per-task cost track requires capture at the request level. [39][40]

**claim 83** — [FACT] langsmith and datadog provide llm observability platforms that capture per-request tokens, latency, and cost. [41][42]
> "langsmith captures traces of llm interactions for debug and cost analysis."

**claim 84** — [SUMP] per-task token and cost capture in khlone artifacts provides sufficient observability for v0 without external platforms. [82]

**claim 85** — [KHUE] should token/cost data be stored per-task, per-clone, or per-zone for optimal observability?

**claim 86** — [FACT] developers report surprise at ai code tool costs without per-session visibility. [69]
> "i had no idea how many tokens were consumed until the monthly bill arrived."

---

## section 15: construction metaphor validation

**claim 87** — [FACT] construction project management uses hierarchical coordination: general contractor > subcontractors > tradespeople. [37][79][80]
> "the general contractor orchestrates subcontractors who each contribute specialized trades to the job site."

**claim 88** — [FACT] construction "zones" are physically isolated work areas on a job site with dedicated crews. [37]
> "work zones delineate areas of responsibility and prevent interference between trades."

**claim 89** — [FACT] the foreman role in construction serves as both delegator and coordinator, which maps to khlone's hero clone pattern. [37][79]
> "the foreman assigns work, inspects quality, and serves as the communication hub between the crew and management."

**claim 90** — [OPIN] construction terminology (site, zone, crew, clone, foreman) provides more intuitive mental models than software terminology (cluster, namespace, pool, instance, scheduler). [37][79]

**claim 91** — [FACT] construction crews are role-specialized (electrician, plumber, carpenter) with clear capability boundaries, which maps to khlone's role-based clone enrollment. [79][80]

**claim 92** — [SUMP] the construction domain metaphor scales to khlone's needs because construction coordination complexity exceeds most software orchestration scenarios. [37][79]

---

## section 16: adoption and market statistics

**claim 93** — [FACT] the stackoverflow 2024 developer survey reports 76% of developers use or plan to use ai code tools. [44]
> "76% of developers are favorable to or already in use of ai tools in their development process."

**claim 94** — [FACT] gartner predicts 75% of enterprise software engineers will use ai code assistants by 2028 (up from less than 10% in 2023). [43]
> "by 2028, 75% of enterprise software engineers will use ai code assistants, up from less than 10% in early 2023."

**claim 95** — [FACT] the ai code tools market includes 50+ products across ide extensions, cli tools, and cloud platforms. [70][71]

**claim 96** — [FACT] mckinsey reports 20-45% developer productivity improvement with ai code tool adoption. [52]
> "developers report 20-45% improvement in task completion speed when ai code tools are adopted."

**claim 97** — [SUMP] the market is saturated with interactive ai code assistants but has zero shell-native orchestrators. [1][2][3][4][5][6][70]

**claim 98** — [OPIN] the market time is favorable for khlone: developers are comfortable with ai code tools but frustrated by their terminal ux. [28][29][44]

**claim 99** — [FACT] deloitte reports that 65% of organizations have moved past pilot stage with ai code generation tools. [51]
> "65% of organizations surveyed have moved beyond pilot programs to scaled deployment of ai code generation."

---

## section 17: strategic predictions

**claim 100** — [SUMP] brain-repl vendors (anthropic, openai) will eventually add headless/daemon modes, but khlone's orchestration layer will remain complementary. [49][82]

**claim 101** — [KHUE] will brain-repl vendors build their own orchestration layers, or will orchestration remain a third-party concern?

**claim 102** — [OPIN] the separation of enrollment (rhachet) from orchestration (khlone) mirrors the separation of concerns in software architecture and will prove durable. [82]

**claim 103** — [SUMP] local-first execution will remain important even as cloud compute scales, because latency, cost, and data sovereignty matter for developer workflows. [82]

**claim 104** — [KHUE] what is the threshold at which developers prefer cloud-hosted clone execution over local execution?

**claim 105** — [FACT] the claude code sdk announcement signals anthropic's intent to support programmatic (non-interactive) integration. [49]

**claim 106** — [OPIN] khlone's value proposition strengthens as brain-repl diversity increases: orchestrate any brain via any role, not just one vendor's tool. [82]

---

## section 18: supplemental claims from prior research

**claim 107** — [FACT] unix domain sockets provide bidirectional, kernel-level ipc without network stack overhead. [23][81]
> "unix domain sockets are fast (kernel-level, no network stack), file-based (easy cleanup, permissions)." — ipc research

**claim 108** — [FACT] mcp (model context protocol) is designed for claude to call tools, not for external systems to call claude; the direction is inverted for khlone's use case. [81]
> "mcp is for claude to call tools; we need the inverse (call claude)." — ipc research

**claim 109** — [FACT] the daemon scope decision is one daemon per zone, one pty per clone. [81]
> "one daemon per zone — the supervisor process; one pty per clone — each clone is a separate brain session." — ipc research

**claim 110** — [FACT] claude code supports `--resume`, `--continue`, `--print`, and `--dangerously-skip-permissions` flags as of may 2025. [81]
> "available flags: --resume, --continue, --print, --dangerously-skip-permissions." — ipc research

**claim 111** — [FACT] the tool landscape for ai code cli access spans claude code (pty/sdk), aider (api), cursor (ide), copilot (ide), codex (sandbox), and continue.dev (ide). [82]

**claim 112** — [FACT] claude code sdk provides `ClaudeCode.query()` for one-shot and `ClaudeCode.stream()` for continuous interaction. [82]
> "sdk methods: ClaudeCode.query() for one-shot, ClaudeCode.stream() for continuous." — access research

---

## section 19: additional worldwide claims

**claim 113** — [FACT] git worktrees are a native git feature (since git 2.5, 2015) that avoids the overhead of full repository clones. [24]
> "git worktree add creates a linked work tree without a full clone of the repository."

**claim 114** — [FACT] process groups in unix allow signal delivery to all processes in a group, which enables clean shutdown of daemon + clone trees. [76]
> "a process group is a collection of related processes that can all be signaled at once."

**claim 115** — [SUMP] the `khlone.yml` configuration file as the single source of site configuration follows established patterns (docker-compose.yml, terraform.tf). [82]

**claim 116** — [FACT] the `--who role++` syntax for inline clone enrollment has no precedent in current cli tools; it is a novel ux pattern. [82]

**claim 117** — [KHUE] how should khlone handle clone enrollment failures (e.g., brain-repl spawn failure, invalid role configuration)?

**claim 118** — [FACT] tab completion for cli tools is implementable via bash/zsh completion files and improves discoverability. [53]
> "gh provides shell completion for bash, zsh, fish, and powershell."

**claim 119** — [SUMP] smart status defaults (pwd-aware scope selection) will reduce the need for explicit scope flags in 80%+ of invocations. [82]

**claim 120** — [KHUE] should khlone provide a tui (terminal ui) mode for richer status display, or keep output strictly text-based?

**claim 121** — [FACT] the `onStop` hook pattern for artifact capture mirrors ci/cd pipeline post-step hooks. [82]

**claim 122** — [OPIN] khlone's differentiation is not in ai capability (that's the brain) but in orchestration ux: dispatch, observe, recover. [82]

**claim 123** — [FACT] no current tool combines all three: (1) fire-and-forget dispatch, (2) task queue with priority, (3) crash recovery with session resume. [1][2][3][4][5][82]

**claim 124** — [SUMP] the v0 feature set (init, ask, act, list, status, watch, talk, log) provides a minimum viable orchestrator. [82]

**claim 125** — [KHUE] what is the right default brain for the hero clone — should khlone prescribe a default, or require explicit configuration?

---

## coverage summary

| category | [FACT] | [SUMP] | [KHUE] | [OPIN] | total |
|----------|--------|--------|--------|--------|-------|
| orchestration frameworks | 4 | 1 | 1 | 1 | 7 |
| multi-agent failure modes | 4 | 1 | 1 | 0 | 6 |
| terminal ux pain | 4 | 1 | 0 | 1 | 6 |
| fire-and-forget gap | 4 | 1 | 1 | 1 | 7 |
| ask/act mode enforcement | 3 | 1 | 1 | 1 | 6 |
| headless cli execution | 5 | 1 | 1 | 0 | 7 |
| queue-based task dispatch | 3 | 1 | 1 | 0 | 5 |
| pty/tmux orchestration | 4 | 1 | 1 | 0 | 6 |
| daemon lifecycle | 4 | 1 | 1 | 0 | 6 |
| crash recovery/checkpoints | 4 | 1 | 1 | 0 | 6 |
| worktree isolation | 3 | 1 | 1 | 0 | 5 |
| cross-repo dispatch | 2 | 1 | 1 | 1 | 5 |
| security/sandbox | 3 | 1 | 1 | 0 | 5 |
| cost track/token management | 4 | 1 | 1 | 0 | 6 |
| construction metaphor | 4 | 1 | 0 | 1 | 6 |
| adoption/market | 5 | 1 | 0 | 1 | 7 |
| strategic predictions | 2 | 2 | 2 | 2 | 8 |
| prior research supplement | 6 | 0 | 0 | 0 | 6 |
| additional worldwide | 4 | 2 | 3 | 1 | 10 |
| **total** | **82** | **16** | **19** | **8** | **125** |

---

## key takeaways

1. **the fire-and-forget gap is real and unserved** — no ai code tool returns the shell immediately after task submission [claims 21-26]

2. **per-task mode enforcement (ask/act) is novel** — current tools enforce permissions at the session level, not the task level [claims 28-33]

3. **the pty + unix socket stack is validated** — prior research confirms this is the correct integration approach for brain-repl orchestration [claims 47-51, 107-110]

4. **crash recovery via two layers (daemon restart + session resume) is sufficient** — the combination covers process-level and conversation-level recovery [claims 59-64]

5. **the construction metaphor holds** — domain research validates that construction coordination patterns (foreman, crew, zone, site) map naturally to clone orchestration [claims 87-92]

6. **the market is ripe** — 76% developer adoption of ai code tools + zero shell-native orchestrators = clear opportunity [claims 93-99]

7. **multi-agent failure modes are well-documented** — khlone's architecture (isolated clones, per-clone queues, hero delegation) avoids the worst pathologies [claims 8-14]

8. **worktree isolation per zone avoids complexity** — git worktrees provide branch-level filesystem isolation without container overhead [claims 65-69]

---

## references to prior research

this document builds on two prior research artifacts:

- **[81]** ipc and process management research — established the unix socket + pty + daemon architecture, rejected mcp, confirmed node-pty as the integration layer
- **[82]** access and tool landscape research — surveyed the ai code cli tool landscape, identified headless execution modes, and mapped the access patterns for each brain-repl vendor

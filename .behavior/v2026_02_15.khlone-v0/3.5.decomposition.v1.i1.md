# khlone v0: decomposition

> eight self-contained blocks that incrementally build toward the full v0 behavior

---

```
 ┌─────────────────────────────────────────────────────────────────────────────┐
 │  stateless: no DAOs, no ~/.khlone/, daemon = state                         │
 │                                                                            │
 │  ┌───────────────────────────────────────┐                                 │
 │  │ 0  BrainCli contract + supplier       │  brain handle exists,           │
 │  │                              13 files │  tested against live CLI        │
 │  └──────────────────┬────────────────────┘                                 │
 │                     │                                                      │
 │                     ▼                                                      │
 │  ┌───────────────────────────────────────┐                                 │
 │  │ A  headless dispatch (stateless)      │  dispatch tasks, instant        │
 │  │                              70 files │  return, shell is free          │
 │  └──┬───────┬───────┬───────────┬────────┘                                 │
 │     │       │       │           │                                          │
 │     ▼       ▼       │           ▼                                          │
 │  ┌──────┐ ┌──────┐  │  ┌─────────────────────────────────┐                │
 │  │ B    │ │ C    │  │  │ D  multi-clone                  │  many workers  │
 │  │watch │ │clone │  │  │ --who, --skill, disrupt         │  per zone,     │
 │  │await │ │crash │  │  │                        18 files │  skill routes  │
 │  │      │ │      │  │  └──────────────┬──────────────────┘                │
 │  │9 file│ │5 file│  │                 │  (E needs D for clone address)    │
 │  └──────┘ └──────┘  │                 ▼                                    │
 │                      │  ┌─────────────────────────────────┐                │
 │  see what  clone     │  │ E  interactive talk              │  drop into    │
 │  clone     crash →   │  │                         3 files │  clone repl   │
 │  does,     restart   │  └─────────────────────────────────┘                │
 │  pipe to             │  (daemon crash → F)                                │
 │  files               │                                                     │
 ├──────────────────────┼─────────────────────────────────────────────────────┤
 │  persistent: DAOs, filesystem, ~/.khlone/ state dir                        │
 │                      │                                                     │
 │                      ▼                                                     │
 │  ┌───────────────────────────────────────┐                                 │
 │  │ F  persistence + artifacts + log      │  state survives daemon          │
 │  │                             24 files │  death, transcript review       │
 │  └──────────────────┬────────────────────┘                                 │
 │                     │                                                      │
 │                     ▼                                                      │
 │  ┌───────────────────────────────────────┐                                 │
 │  │ G  cross-scope (--zone, --site)       │  reach into other zones        │
 │  │                             35 files │  and repos from anywhere        │
 │  └───────────────────────────────────────┘                                 │
 │                                                                            │
 └──────────────────────────────────────────────────────────── 177 files total┘
```

---

## why decompose

the blueprint declares ~177 files across 5 layers (plus 13 in `_topublish`), 49 domain operations, 8 daos, 15 IPC message types, a daemon process, and BrainCli integration. no single pass of one brain's focus can deliver all of this.

instead: decompose into discrete blocks. each block ships a complete behavioral increment — testable, usable, playtest-able. no dead code. no half-built subsystems that wait for a future block to become functional.

---

## the eight blocks

```
block 0: BrainCli contract + claude supplier (_topublish)
│
block A: headless dispatch (stateless)  ← requires 0
    ├── block B: passive observe (watch + await)
    ├── block C: crash recovery (in-daemon, stateless)
    ├── block D: multi-clone (--who, --skill, --when disrupt)
    │   └── block E: interactive talk  ← requires D (clone address for --who target)
    ├── block F: persistence + artifacts + log
    │   └── block G: cross-scope (--zone, --site)  ← requires F (DAOs for cross-scope state)
    └── (B, C are fully independent of all siblings)
```

**dependency rule:** each block depends on the blocks above it in the tree. B and C are independent of all siblings — build in any order after A. D, E, F, G have the dependencies shown: E requires D (clone address), G requires F (persistence).

**recommended order:** 0 → A → B → C → D → E → F → G

**rationale for order:**
- 0 (BrainCli) first — the daemon has no brain process to manage without it
- A (headless dispatch) next — the core loop: spawn daemon, boot hero, queue tasks, execute
- B (watch/await) first after A — makes dispatch observable ("what did it do?")
- C (crash recovery) next — makes dispatch reliable ("it won't lose my work")
- D (multi-clone) next — unlocks the crew model ("more than one worker")
- E (interactive talk) after D — interactive mode needs clone address from D
- F (persistence) after dispatch stabilizes — adds durability, transcript, artifacts
- G (cross-scope) last — extends reach to other zones and sites

**key architectural choice:** blocks 0 through E are **stateless** — the daemon holds all state in memory. no DAOs, no `~/.khlone/` directory, no disk writes beyond pid files and the unix socket. persistence arrives in block F, when the behavioral need for durability (transcript review, artifacts, daemon-restart survival) justifies the infrastructure cost.

---

## block 0: BrainCli contract + claude supplier

> the BrainCli interface and its first supplier (claude code) exist, tested against a live CLI process. khlone's daemon has a real handle to code against.

### what ships

built inside khlone under `src/_topublish/` via the `_topublish` pattern (see z2 zoomin). develops the contract in-repo, proves it against real CLI processes, ejects to rhachet once stable.

**`_topublish/rhachet/`** — the interface contract:
- `BrainCli.ts` — the interface: `terminal: {}` (i/o surface), `executor: {}` (process lifecycle), `ask()`, `act()`
- `genBrainCli.ts` — factory: brain slug → BrainCli handle (routes to supplier)
- `index.ts` — re-exports
- imports `BrainOutput`, `BrainOutputMetrics`, `BrainEpisode`, `BrainSeries` from the published rhachet package — no re-declaration

**`_topublish/rhachet-brains-anthropic/`** — the claude supplier:
- `BrainCli.config.ts` — `CONFIG_BY_CLI_SLUG`, `AnthropicBrainCliSlug` type
- `genBrainCli.ts` — factory: slug → handle via claude terminal spawn
- `getOneBrainOutputFromStreamJson.ts` — parse nd-JSON events → BrainOutput
- `getOneDispatchArgs.ts` — compute CLI args for dispatch mode (`-p --input-format stream-json --output-format stream-json --allowedTools`)
- `getOneInteractArgs.ts` — compute CLI args for interact mode (`--resume <session-id>`)
- `index.ts` — exports

### what is proven

| capability | how |
|---|---|
| `executor.boot({ mode: 'dispatch' })` | spawns `claude -p` with structured i/o, captures session_id |
| `executor.boot({ mode: 'interact' })` | kills dispatch process, spawns `claude --resume` in raw terminal mode |
| `ask({ prompt })` | sends nd-JSON input, collects structured BrainOutput with metrics |
| `act({ prompt })` | same as ask, different `--allowedTools` set at boot time |
| `terminal.onData` / `terminal.onExit` | raw byte stream and exit signal from CLI process |
| `executor.kill()` | clean termination |
| crash → `executor.boot()` | series preserved on handle, respawn with `--resume` — new episode, same series |
| ask vs act enforcement | `--allowedTools` restricts tool access per mode; never `--dangerously-skip-permissions` |

### playtests

```ts
// integration test — real claude CLI process
const handle = genBrainCli({ slug: 'claude/code', cwd: tempDir, role: 'test' });
await handle.executor.boot({ mode: 'dispatch' });

const result = await handle.ask({ prompt: 'respond with exactly: hello' });
expect(result.output).toContain('hello');
expect(result.metrics.size.tokens.input).toBeGreaterThan(0);
expect(handle.series).not.toBeNull();

handle.executor.kill();
```

### boundaries

- **no khlone state.** no domain objects, no daos, no orchestrator. pure BrainCli contract + supplier.
- **no daemon.** the handle is used directly in tests. daemon consumption comes in block A.
- **claude supplier only.** codex, opencode, gemini suppliers follow the same `clis/` pattern later.

### file count

| layer | prod | test | total |
|-------|------|------|-------|
| `_topublish/rhachet` (interface + factory) | 3 | 0 | 3 |
| `_topublish/rhachet-brains-anthropic` (clis/) | 6 | 4 | 10 |
| **subtotal** | **9** | **4** | **13** |

### ejection path

once proven against khlone's daemon, dispatch, talk mode, and crash recovery:

1. copy `_topublish/rhachet/` → rhachet core
2. copy `_topublish/rhachet-brains-anthropic/clis/` → rhachet-brains-anthropic alongside extant `atoms/`, `repls/`, `hooks/`
3. publish rhachet + rhachet-brains-anthropic
4. sedreplace khlone imports: `from '../../_topublish/rhachet'` → `from 'rhachet'`
5. delete `_topublish/`

mechanical. zero logic changes.

---

## block A: headless dispatch (stateless)

> a single hero clone boots, receives tasks, and executes them headlessly via BrainCli. the daemon holds all state in memory — zero persistence, zero DAOs, zero `~/.khlone/`.

### what ships

**domain objects (in-memory shapes — 11 files):**
- SiteManifest — parsed khlone.yml config
- Zone, ZoneAddress — zone identity
- ZoneDaemon, DaemonConnection — daemon metadata + IPC handle type
- Clone, CloneAddress, CloneStatus — clone identity + state
- Task, TaskMode, TaskStatus — task identity + state

**infra (domain-free utilities — 9 prod, 9 test):**
- ipc: createIpcServer, createIpcClient, IpcMessage (subset: enqueue, status, status-response, task-complete, kill, ack, error)
- filesystem: getOneGitroot, getOneGitBranch — cwd derivation (read-only — no persistence writes)
- process: spawnDetached, isProcessAlive, writePidFile, readPidFile — daemon lifecycle

note: no PTY infra here — BrainCli abstracts PTY away. the supplier (block 0) owns all PTY lifecycle internally. khlone's daemon calls `brainCli.ask()`, `.act()`, `.terminal.write()`, `.terminal.onData`, `.terminal.onExit` — never touches PTY directly.

**domain operations (12 prod, 12 test):**
- config: getOneSiteManifest (parse khlone.yml), getOneContextCli (derive zone + config from cwd), getOneRoleSlugByAlias, getOneBrainSlugByAlias
- zone: getOneZoneAddress (parse @branch format)
- clone: getOneCloneSlug (compute role.n for display)
- daemon: setZoneDaemon (spawn), getOneZoneDaemon (discover via pid), genZoneDaemon (find alive or spawn), getOneDaemonConnection (connect IPC)
- dispatch: dispatchTask (brainCli.ask/act), enqueueTask (IPC to daemon)

**cli + entry (8 prod):**
- invoke.ts (commander program, routes verbs)
- invokeInit (spawn daemon + verify config)
- invokeAsk, invokeAct (dispatch task)
- invokeStatus (query daemon via IPC, render zone-level view)
- sdk.ts (public exports)
- bin/run, bin/run.jit (shell entry)

**daemon entry (1 prod):**
- the supervisor process: boot hero brainCli, listen on unix socket, dequeue tasks, execute via brainCli.ask() or brainCli.act(), respond to IPC status queries

### how state works without persistence

the daemon **is** the state. all zone, clone, and task state lives in daemon memory:

```
daemon process (pid 1234)
├── zone: { address: '@feat/auth', site: 'ehmpathy/myrepo' }
├── hero: { slug: 'foreman.1', brainCli: <handle>, status: 'active' }
├── tasks:
│   ├── task-abc-123: { mode: 'act', prompt: '...', status: 'active' }
│   └── task-def-456: { mode: 'ask', prompt: '...', status: 'queued' }
└── ipc: unix socket at /tmp/khlone-zone-{hash}.sock
```

the CLI discovers the daemon via pid file → connects via unix socket → queries or dispatches via IPC. no filesystem state beyond the pid file and socket.

**tradeoff:** daemon death = total state loss. acceptable for blocks A through E — recovery comes with persistence in block F.

### usecases fulfilled

| usecase | status |
|---------|--------|
| usecase.1: instant dispatch | **yes** — ask/act return to shell at once, task queued to hero |
| usecase.2: task mode enforcement | **yes** — ask → brainCli.ask(), act → brainCli.act() |
| usecase.3: queue stack (enqueue) | **partial** — FIFO enqueue works; --prioritize deferred to D |
| usecase.6: status (basic) | **partial** — zone-level via IPC query; smart defaults deferred to G |

### playtests

```sh
$ khlone act "implement auth"

✓ task-abc-123 → foreman.1 (@feat/auth)
$ _                              # instant return, shell is yours

$ khlone ask "what files changed?"

✓ task-def-456 → foreman.1 (@feat/auth)

$ khlone act "add tests"

✓ task-ghi-789 → foreman.1 (@feat/auth)

$ khlone status

zone @feat/auth (local)
├─ ● foreman.1  45%  implement auth
└─ queue 2 tasks
```

### boundaries

- **hero clone only.** no --who flag. all tasks queue to the single hero.
- **no observe.** no watch, no talk, no await. dispatch is fire-and-check (use status).
- **no crash recovery.** if the clone crashes, it stays dead until next daemon restart.
- **no --prioritize, no --when disrupt.** tasks enqueue in FIFO order.
- **stateless.** daemon holds all state in memory. daemon death = state loss. durability comes in block F.
- **IPC subset.** only enqueue, status, task-complete, kill, ack, error messages.

### what is NOT here

- no `~/.khlone/` directory
- no DAOs, no json/jsonl persistence
- no `khlone list` (needs multi-zone awareness from block G)
- no smart status defaults (needs orchestrator from block G)
- no cross-zone/cross-site dispatch
- no artifacts, no transcript capture

### file count

| layer | prod | test | total |
|-------|------|------|-------|
| domain.objects (11 shapes) | 11 | 0 | 11 |
| infra (ipc + filesystem + process) | 9 | 9 | 18 |
| domain.operations (config, zone, clone, daemon, dispatch) | 12 | 12 | 24 |
| contract/cli + sdk | 6 | 0 | 6 |
| bin | 2 | 0 | 2 |
| daemon entry | 1 | 0 | 1 |
| test assets | 4 | 0 | 4 |
| acceptance (act, ask, queue-partial, status-basic) | 0 | 4 | 4 |
| **subtotal** | **45** | **25** | **70** |
| **cumulative (with block 0)** | **54** | **29** | **83** |

---

## block B: passive observe (watch + await)

> see what the clone does without interrupt. pipe output to files.

### what ships

- observe operations: setTerminalToWatchClone, setTerminalToDetach, setTerminalToAwaitTask
- IPC messages: attach, detach, output, task-complete (extended)
- cli: `khlone watch`, `--watch` flag, `--await` flag

### usecases fulfilled

| usecase | status |
|---------|--------|
| usecase.4: observe (watch) | **yes** — stream output, ctrl+c returns |
| usecase.5: block output (await) | **yes** — block until done, pipe to file |

### playtests

```sh
$ khlone act "implement auth" --watch
✓ task-abc-123 → foreman.1 (@feat/auth)

lets watch...

             ┬
● foreman.1  │ read src/auth.ts
● foreman.1  │ edit: add jwt validation
^C
$ _                              # ctrl+c, back to shell

$ khlone ask "summarize changes" --await >> summary.md
# blocks until done, output captured in file
```

### boundaries

- **passive only.** no interactive input. watch streams output; await blocks and captures.
- **no talk mode.** interactive conversation deferred to block E.

### file count

| layer | prod | test | total |
|-------|------|------|-------|
| domain.operations (observe — subset) | 3 | 3 | 6 |
| contract/cli (watch + flag updates) | 1 | 0 | 1 |
| acceptance (watch, await) | 0 | 2 | 2 |
| **subtotal** | **4** | **5** | **9** |
| **cumulative** | **58** | **34** | **92** |

---

## block C: crash recovery (in-daemon, stateless)

> clone crashes are caught, isolated, and recovered via BrainSeries continuation. peers survive. all state stays in daemon memory — no persistence needed for clone-level recovery.

### what ships

- daemon: `brainCli.terminal.onExit` callback per clone handle
- daemon: `genCloneViaDaemon` — ensure clone process alive; respawn via `setCloneViaDaemon` if dead
- daemon: `setCloneViaDaemon` — respawn clone's brainCli via BrainSeries continuation (`executor.boot`)
- task resume from in-memory state (daemon knows which task was active)

### why no persistence

the daemon is still alive — it holds the clone's series ref, the task queue, and the active task state in memory. `brainCli.executor.boot()` uses the series ref from the handle. no disk read required.

**daemon-level crash** (the supervisor dies) is a separate concern — it requires persistence (block F). block C handles **clone-level crash** only.

### usecases fulfilled

| usecase | status |
|---------|--------|
| usecase.12: crash recovery (clone-level) | **yes** — crash → restart → resume via BrainSeries |

### playtests

```sh
# clone crashes mid-task
# daemon detects via brainCli.terminal.onExit callback
# daemon boots brainCli via handle (series preserved)
# task resumes — new episode, same series
# peer clones (from block D onward) unaffected

$ khlone status
zone @feat/auth (local)
├─ ● foreman.1  restarted  implement auth (resumed)
└─ queue 0 tasks
```

### boundaries

- **clone crash only.** daemon stays alive. daemon-level crash recovery requires block F.
- **single clone in practice.** with only hero clone (block A), crash isolation is trivial. multi-clone crash isolation acceptance tested after block D.

### file count

| layer | prod | test | total |
|-------|------|------|-------|
| daemon enhancements (onExit handler, boot path) | 2 | 2 | 4 |
| acceptance (crash) | 0 | 1 | 1 |
| **subtotal** | **2** | **3** | **5** |
| **cumulative** | **60** | **37** | **97** |

---

## block D: multi-clone (--who, --skill, --when disrupt)

> more than one clone per zone. address them by role, brain, and index. skills route to the capable role. disrupt pauses current work.

### what ships

- clone operations: getOneCloneAddress (parse --who token), genClone (find-or-enroll with alias lookup), getOneClone (find extant), setClone (enroll new), getOneCloneNextIndex
- dispatch operations: dispatchSkill (route to capable role), disruptClone (pause current task)
- task operations: setTaskPriority (queue at front)
- IPC messages: disrupt
- cli: --who, --skill, --when, --prioritize flags on ask/act

### usecases fulfilled

| usecase | status |
|---------|--------|
| usecase.3: queue stack (full) | **yes** — enqueue, --prioritize, --when disrupt |
| usecase.8: clone address | **yes** — full --who grammar: `[role][.n][@brain][++]` |
| usecase.9: skill dispatch | **yes** — route to capable role, error on ambiguous |

### playtests

```sh
$ khlone act "research patterns" --who researcher++
✓ enrolled researcher.1
✓ task-ghi-789 → researcher.1 (@feat/auth)

$ khlone ask "status?" --when disrupt
# pauses hero's current task, answers at once

$ khlone act "review auth" --who reviewer++
✓ enrolled reviewer.1
✓ task-jkl-012 → reviewer.1 (@feat/auth)

$ khlone status
zone @feat/auth (local)
├─ ● foreman.1    claude  67%  2 tasks
├─ ● researcher.1 claude  12%  1 task
└─ ● reviewer.1   claude   5%  1 task

$ khlone ask --skill review.architecture
✓ task-mno-345 → reviewer.1 (skill review.architecture)
```

### boundaries

- **local zone only.** all clones in the same zone on the same machine. cross-zone deferred to block G.
- **no talk with specific clone.** talk mode deferred to block E (it needs clone address from this block first).

### file count

| layer | prod | test | total |
|-------|------|------|-------|
| domain.operations (clone — 5, dispatch — 2, task — 1) | 8 | 8 | 16 |
| acceptance (who, skill, queue — full) | 0 | 2 | 2 |
| **subtotal** | **8** | **10** | **18** |
| **cumulative** | **68** | **47** | **115** |

---

## block E: interactive talk

> drop into a clone's session for direct conversation. daemon boots to interact mode, relays raw terminal bytes via brainCli handle.

### what ships

- observe operations: setTerminalToTalkWithClone
- IPC messages: talk, talk-ready, talk-end, input, resize
- daemon: brainCli.executor.boot({ mode: 'interact' }) + byte relay + boot back to dispatch on exit
- cli: `khlone talk`, `--talk` flag

### usecases fulfilled

| usecase | status |
|---------|--------|
| usecase.4: observe (talk) | **yes** — interactive session, /exit returns to shell |

### playtests

```sh
$ khlone talk
# drops into foreman.1's session

$ khlone talk mechanic.1
# drops into mechanic.1's session

$ khlone act "task" --talk
✓ task-pqr-678 → foreman.1
# drops into interactive session

# /exit returns to shell
# daemon boots brainCli to dispatch mode
```

### boundaries

- **local only.** no remote talk. cross-zone talk deferred to block G.

### file count

| layer | prod | test | total |
|-------|------|------|-------|
| domain.operations (observe — talk) | 1 | 1 | 2 |
| acceptance (talk) | 0 | 1 | 1 |
| **subtotal** | **1** | **2** | **3** |
| **cumulative** | **69** | **49** | **118** |

---

## block F: persistence + artifacts + log

> state survives daemon death. tasks capture structured output on completion. transcripts are reviewable. this block introduces the entire persistence layer — DAOs, filesystem helpers, and the `~/.khlone/` state directory.

### what ships

**infra/filesystem (persistence helpers — 4 prod, 4 test):**
- readJsonFile, writeJsonFile — json read/write with atomic tmp+rename
- appendJsonlFile, readJsonlFile — jsonl append/read for transcript

**domain objects (3 files):**
- CloneCheckpoint — resume point for crash recovery
- CloneTranscriptEmission — single transcript entry
- TaskArtifact — captured output (summary, complete, tokens)

**access/daos (6 files):**
- daoZone — persist zone state under `~/.khlone/`
- daoCrew — persist clone registry per zone
- daoClone — persist clone state (status, series ref, pid)
- daoTask — persist task state + artifacts
- daoCloneCheckpoint — persist checkpoint for daemon-restart resume
- daoCloneTranscript — append-only transcript per clone

**domain operations (2 prod, 2 test):**
- genTaskArtifacts — post-task: prompt clone for summary via onStop hooks
- setTaskArtifacts — write artifacts to task state

**daemon enhancements:**
- persist state to disk on mutation: task complete → daoTask, clone status → daoClone
- persist checkpoint on clone crash → daoCloneCheckpoint (enables daemon-level crash recovery)
- capture transcript on brainCli.terminal.onData → daoCloneTranscript.append

**cli (1 prod):**
- invokeLog — `khlone log`, `--who` filter for log

### what this unlocks

| capability | before block F | after block F |
|---|---|---|
| daemon dies | all state lost | state on disk, daemon can resume |
| "what did the clone do?" | must ask via IPC while daemon is alive | `khlone log` reads transcript from disk |
| task completion data | ephemeral, lost when daemon exits | artifacts persisted per task |
| clone crash + daemon restart | task lost | checkpoint → resume from last known state |
| `khlone status` with dead daemon | "daemon not found" | reads last-known state from disk |

### usecases fulfilled

| usecase | status |
|---------|--------|
| usecase.12: crash recovery (daemon-level) | **yes** — checkpoint + transcript survive daemon death |
| usecase.13: task artifacts | **yes** — onStop hooks capture summary, complete, tokens |
| usecase.14: transcript access | **yes** — `khlone log` reads persisted transcript |

### playtests

```sh
$ khlone status --task task-abc-123
task task-abc-123
├─ mode      act
├─ prompt    "implement auth"
├─ clone     foreman.1
├─ status    ✓ done
└─ artifacts
   ├─ summary   added jwt validation to auth module
   ├─ complete  yes
   └─ tokens    4,521

$ khlone log
# shows transcript for default clone

$ khlone log --who mechanic.1
# shows transcript for mechanic.1

# daemon dies and restarts — state survives
$ khlone status
zone @feat/auth (local)
├─ ● foreman.1  resumed  implement auth (from checkpoint)
└─ queue 1 task
```

### boundaries

- **local zone only.** persistence is per-zone under `~/.khlone/`. cross-zone and cross-site registry deferred to block G.
- **no orchestrator registry.** `~/.khlone/` exists but has no global site index yet.

### file count

| layer | prod | test | total |
|-------|------|------|-------|
| domain.objects (3: checkpoint, transcript emission, artifact) | 3 | 0 | 3 |
| infra/filesystem (persistence helpers) | 4 | 4 | 8 |
| access/daos (6: zone, crew, clone, task, checkpoint, transcript) | 6 | 0 | 6 |
| domain.operations/task (artifacts) | 2 | 2 | 4 |
| contract/cli (log) | 1 | 0 | 1 |
| acceptance (artifacts, log) | 0 | 2 | 2 |
| **subtotal** | **16** | **8** | **24** |
| **cumulative** | **85** | **57** | **142** |

---

## block G: cross-scope (--zone, --site)

> reach into other zones and sites from anywhere. the orchestrator registry makes cross-scope address work. full `khlone list` and smart status defaults arrive here.

### what ships

**domain objects (2 files):**
- Orchestrator — global state across machine
- Site — repo-level container

**access/daos (2 files):**
- daoOrchestrator — global registry under `~/.khlone/`
- daoSite — site registry

**domain operations (13 prod, 13 test):**
- orchestrator: genOrchestrator (load or init `~/.khlone/`), setSite (register site), getOneSiteBySlug, getAllSites
- site: getOneSite, genSite (find or register), getAllZonesForSite
- zone: genZone (find extant or create), setZone (persist zone state), getOneZoneByAddress (cross-zone lookup), getAllClonesForZone (DAO-backed), getAllTasksForZone (DAO-backed)
- status: getOneStatusSite, getOneStatusOrchestrator, getOneStatusScope (smart defaults: feature branch → zone, main → site, no-git → orchestrator)

**cli (1 prod):**
- invokeList — `khlone list sites|zones|crews|tasks`
- invokeStatus enhanced with smart scope defaults

### usecases fulfilled

| usecase | status |
|---------|--------|
| usecase.6: status (full) | **yes** — smart defaults based on pwd context |
| usecase.7: resource enumeration | **yes** — list sites, zones, crews, tasks |
| usecase.10: cross-zone dispatch | **yes** — --zone dispatches to different branch |
| usecase.11: cross-site dispatch | **yes** — --site dispatches to different repo |

### playtests

```sh
$ khlone status --zone @feat/invoice
zone @feat/invoice (local)
├─ ● mechanic.1  45%  add invoice api
└─ queue 0 tasks

$ khlone act "fix bug" --zone @hotfix/typo
✓ init @hotfix/typo → foreman.1
✓ task-stu-901 → foreman.1 (@hotfix/typo)

$ khlone ask "how does auth work" --zone svc-auth@main --await >> notes.md
# dispatches to svc-auth site, main zone

$ khlone list zones
site ehmpathy/myrepo
├─ @main          ○ foreman.1
├─ @feat/auth     ● foreman.1 (67%), ○ researcher.1
└─ @hotfix/typo   ✓ foreman.1

$ khlone status --site ahbode/svc-jobs
site ahbode/svc-jobs
├─ @main          ○ foreman.1
└─ @feat/invoice  ● foreman.1 (45%)
```

### boundaries

- **all v0 behavior complete.** this is the final block. all usecases are fulfilled.

### file count

| layer | prod | test | total |
|-------|------|------|-------|
| domain.objects (2: orchestrator, site) | 2 | 0 | 2 |
| access/daos (2: orchestrator, site) | 2 | 0 | 2 |
| domain.operations (orchestrator, site, zone, status) | 13 | 13 | 26 |
| contract/cli (list + status smart defaults) | 1 | 0 | 1 |
| acceptance (crosszone, crosssite, list, status-full) | 0 | 4 | 4 |
| **subtotal** | **18** | **17** | **35** |
| **cumulative** | **103** | **74** | **177** |

---

## cumulative usecase coverage

| block | usecases fulfilled | cumulative total |
|-------|--------------------|------------------|
| 0: BrainCli contract | — (prerequisite, no khlone usecase) | 0 |
| A: headless dispatch | 1, 2, 3 (partial), 6 (basic) | 4 (2 partial) |
| B: passive observe | 4 (watch), 5 | 6 (2 partial) |
| C: crash recovery (clone) | 12 (clone-level) | 7 (3 partial) |
| D: multi-clone | 3 (full), 8, 9 | 9 (2 partial) |
| E: interactive talk | 4 (full) | 9 (1 partial) |
| F: persistence + artifacts + log | 12 (full), 13, 14 | 12 |
| G: cross-scope | 6 (full), 7, 10, 11 | **14 (all)** |

block 0 fulfills no khlone usecase directly — it is the foundation contract that block A consumes. its deliverable is a proven BrainCli handle that can boot, dispatch, and recover a real `claude` CLI process.

error experiences from the criteria are covered by the block that introduces the relevant feature — e.g., "not in a git repo" errors are in block A, "unknown role" errors are in block D, "atom-only supplier" errors are in block A (brainCli boot).

---

## operation-to-block matrix

the blueprint declares 49 domain operations across 10 subdomains. this matrix maps each operation to the block that first introduces it.

**legend:** operations marked with `*` are implicit in their block's handoff (needed by the codepath but not explicitly named in the handoff's "what to build" scope).

### clone/ (6 operations)

| operation | block | notes |
|-----------|-------|-------|
| getOneCloneSlug | A | compute `role.n` for hero |
| getOneCloneAddress | D | parse `--who` token |
| getOneClone | D | find extant clone |
| setClone | D | enroll new clone |
| genClone | D | find-or-enroll with alias lookup |
| getOneCloneNextIndex | D | next index for role |

### config/ (5 operations)

| operation | block | notes |
|-----------|-------|-------|
| getOneSiteManifest | A | parse khlone.yml |
| genSiteManifest | A* | scaffold khlone.yml (implicit in invokeInit) |
| getOneContextCli | A | derive zone + config from cwd |
| getOneRoleSlugByAlias | A | alias lookup |
| getOneBrainSlugByAlias | A | alias lookup |

### daemon/ (6 operations)

| operation | block | notes |
|-----------|-------|-------|
| setZoneDaemon | A | spawn daemon process |
| getOneZoneDaemon | A | discover via pid file |
| genZoneDaemon | A | find alive or spawn |
| getOneDaemonConnection | A | connect IPC |
| genCloneViaDaemon | C | ensure clone process alive; respawn if dead |
| setCloneViaDaemon | C | respawn brainCli via BrainSeries continuation |

### dispatch/ (4 operations)

| operation | block | notes |
|-----------|-------|-------|
| dispatchTask | A | brainCli.ask() / .act() |
| enqueueTask | A | IPC to daemon |
| dispatchSkill | D | route to capable role |
| disruptClone | D | pause current task |

### observe/ (4 operations)

| operation | block | notes |
|-----------|-------|-------|
| setTerminalToWatchClone | B | stream clone output |
| setTerminalToDetach | B | stop stream |
| setTerminalToAwaitTask | B | block until done |
| setTerminalToTalkWithClone | E | interactive session |

### orchestrator/ (4 operations)

| operation | block | notes |
|-----------|-------|-------|
| genOrchestrator | G | load or init `~/.khlone/` |
| setSite | G | register site in orchestrator |
| getOneSiteBySlug | G | lookup by slug |
| getAllSites | G | list all sites |

### site/ (3 operations)

| operation | block | notes |
|-----------|-------|-------|
| getOneSite | G | load site from gitroot |
| genSite | G | find or register |
| getAllZonesForSite | G | list zones for site |

### status/ (6 operations)

| operation | block | notes |
|-----------|-------|-------|
| getOneStatusZone | A* | zone-level status (implicit in invokeStatus) |
| getOneStatusTask | A* | task detail view (implicit in invokeStatus) |
| getOneStatusClone | A* | clone detail view (implicit in invokeStatus) |
| getOneStatusSite | G | site-level status |
| getOneStatusOrchestrator | G | orchestrator-level status |
| getOneStatusScope | G | smart scope defaults based on pwd |

### task/ (5 operations)

| operation | block | notes |
|-----------|-------|-------|
| genTask | A* | create task entity (implicit in dispatch flow) |
| getOneTaskSlug | A* | generate task-{uuid} (implicit in genTask) |
| setTaskPriority | D | queue at front (`--prioritize`) |
| genTaskArtifacts | F | post-task onStop hooks |
| setTaskArtifacts | F | write artifacts to task state |

### zone/ (6 operations)

| operation | block | notes |
|-----------|-------|-------|
| getOneZoneAddress | A | parse `@branch` format |
| setZone | G | persist zone state (DAO) |
| genZone | G | find extant or create zone (DAO) |
| getOneZoneByAddress | G | cross-zone lookup |
| getAllClonesForZone | G | DAO-backed clone list |
| getAllTasksForZone | G | DAO-backed task list |

### per-block totals

| block | operations | notes |
|-------|-----------|-------|
| A | 18 (12 explicit + 6 implicit) | handoff names 12; genSiteManifest, genTask, getOneTaskSlug, getOneStatusZone/Task/Clone are implicit |
| B | 3 | |
| C | 2 | |
| D | 8 | |
| E | 1 | |
| F | 2 | |
| G | 15 | |
| **total** | **49** | matches blueprint |

### CLI two-phase model

block A declares all 8 CLI commands in `invoke.ts` (commander program), but only implements 4 command bodies:

| CLI command | declared | body implemented |
|-------------|----------|------------------|
| `invokeInit` | A | A |
| `invokeAsk` | A | A |
| `invokeAct` | A | A |
| `invokeStatus` | A | A (basic) → G (smart defaults) |
| `invokeWatch` | A | B |
| `invokeTalk` | A | E |
| `invokeList` | A | G |
| `invokeLog` | A | F |

the stub commands in block A throw "not yet available" errors until their block lands. this is why block A's file count includes all 8 CLI files (6 prod in contract/cli + 2 bin) even though only 4 have real implementations.

---

## summary

| block | what | depends on | usecases | prod files | test files |
|-------|------|------------|----------|------------|------------|
| **0** | BrainCli contract + claude supplier | — | — | 9 | 4 |
| **A** | headless dispatch (stateless) | 0 | 1, 2, 3p, 6p | 45 | 25 |
| **B** | passive observe (watch + await) | A | 4w, 5 | 4 | 5 |
| **C** | crash recovery (clone-level) | A | 12c | 2 | 3 |
| **D** | multi-clone (--who, --skill, disrupt) | A | 3f, 8, 9 | 8 | 10 |
| **E** | interactive talk | A, D | 4t | 1 | 2 |
| **F** | persistence + artifacts + log | A | 12d, 13, 14 | 16 | 8 |
| **G** | cross-scope (--zone, --site, list) | A, F | 6f, 7, 10, 11 | 18 | 17 |
| | | **total** | **14** | **103** | **74** |

**block 0** delivers a proven BrainCli handle. **block A** is the keystone — once stateless headless dispatch works, all other blocks are independent and can be built in any order (except E needs D, and G needs F). the recommended order (B → C → D → E → F → G) maximizes usability at each step, but any valid permutation works.

**the stateless-first principle:** blocks 0 through E carry zero persistence. the daemon holds all state in memory. this keeps the first five khlone blocks focused on behavior — dispatch, observe, recover, multi-clone, talk — without the overhead of DAOs, filesystem writes, or the `~/.khlone/` state directory. persistence enters in block F when durability becomes the behavioral need (artifacts, transcript, daemon-restart survival). cross-scope state (orchestrator registry, site index) enters in block G when reach becomes the behavioral need.
